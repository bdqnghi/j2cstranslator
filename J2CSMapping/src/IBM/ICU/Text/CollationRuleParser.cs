// --------------------------------------------------------------------------------------------------
// This file was automatically generated by J2CS Translator (http://j2cstranslator.sourceforge.net/). 
// Version 1.3.6.20101125_01     
// 12/2/10 11:30 AM    
// ${CustomMessageForDisclaimer}                                                                             
// --------------------------------------------------------------------------------------------------
 /// <summary>
/// Copyright (C) 1996-2007, International Business Machines Corporation and    
/// others. All Rights Reserved.                                                
/// </summary>
///
namespace IBM.ICU.Text {
	
	using ILOG.J2CsMapping.Util;
	using System;
	using System.Collections;
	using System.Collections.Generic;
	using System.ComponentModel;
	using System.IO;
	using System.Runtime.CompilerServices;
	using System.Text;
	
	/// <summary>
	/// Class for parsing collation rules, produces a list of tokens that will be
	/// turned into collation elements
	/// </summary>
	///
	/// @draft 2.2
	internal sealed class CollationRuleParser {
	    // public data members ---------------------------------------------------
	
	    // package private constructors ------------------------------------------
	
	    /// <summary>
	    /// <p>
	    /// RuleBasedCollator constructor that takes the rules. Please see
	    /// RuleBasedCollator class description for more details on the collation
	    /// rule syntax.
	    /// </p>
	    /// </summary>
	    ///
	    /// <seealso cref="T:System.Globalization.CultureInfo"/>
	    /// <param name="rules">the collation rules to build the collation table from.</param>
	    /// <exception cref="ParseException">thrown when argument rules have an invalid syntax.</exception>
	    /// @draft 2.2
	    internal CollationRuleParser(String rules) {
	        this.m_utilToken_ = new CollationRuleParser.Token ();
	        this.m_UCAColEIter_ = IBM.ICU.Text.RuleBasedCollator.UCA_
	                .GetCollationElementIterator("");
	        this.m_utilCEBuffer_ = new int[2];
	        this.m_optionarg_ = 0;
	        ExtractSetsFromRules(rules);
	        m_source_ = new StringBuilder(IBM.ICU.Text.Normalizer.Decompose(rules, false).Trim());
	        m_rules_ = m_source_.ToString();
	        m_current_ = 0;
	        m_extraCurrent_ = m_source_.Length;
	        m_variableTop_ = null;
	        m_parsedToken_ = new CollationRuleParser.ParsedToken ();
	        m_hashTable_ = new Hashtable();
	        m_options_ = new CollationRuleParser.OptionSet (IBM.ICU.Text.RuleBasedCollator.UCA_);
	        m_listHeader_ = new CollationRuleParser.TokenListHeader [512];
	        m_resultLength_ = 0;
	        // call assembleTokenList() manually, so that we can
	        // init a parser and manually parse tokens
	        // assembleTokenList();
	    }
	
	    // package private inner classes -----------------------------------------
	
	    /// <summary>
	    /// Collation options set
	    /// </summary>
	    ///
	    internal class OptionSet {
	        // package private constructor ---------------------------------------
	
	        /// <summary>
	        /// Initializes the option set with the argument collators
	        /// </summary>
	        ///
	        /// <param name="collator">option to use</param>
	        internal OptionSet(RuleBasedCollator collator) {
	            m_variableTopValue_ = collator.m_variableTopValue_;
	            m_isFrenchCollation_ = collator.IsFrenchCollation();
	            m_isAlternateHandlingShifted_ = collator
	                    .IsAlternateHandlingShifted();
	            m_caseFirst_ = collator.m_caseFirst_;
	            m_isCaseLevel_ = collator.IsCaseLevel();
	            m_decomposition_ = collator.GetDecomposition();
	            m_strength_ = collator.GetStrength();
	            m_isHiragana4_ = collator.m_isHiragana4_;
	        }
	
	        // package private data members --------------------------------------
	
	        internal int m_variableTopValue_;
	
	        internal bool m_isFrenchCollation_;
	
	        /// <summary>
	        /// Attribute for handling variable elements
	        /// </summary>
	        ///
	        internal bool m_isAlternateHandlingShifted_;
	
	        /// <summary>
	        /// who goes first, lower case or uppercase
	        /// </summary>
	        ///
	        internal int m_caseFirst_;
	
	        /// <summary>
	        /// do we have an extra case level
	        /// </summary>
	        ///
	        internal bool m_isCaseLevel_;
	
	        /// <summary>
	        /// attribute for normalization
	        /// </summary>
	        ///
	        internal int m_decomposition_;
	
	        /// <summary>
	        /// attribute for strength
	        /// </summary>
	        ///
	        internal int m_strength_;
	
	        /// <summary>
	        /// attribute for special Hiragana
	        /// </summary>
	        ///
	        internal bool m_isHiragana4_;
	    }
	
	    /// <summary>
	    /// List of tokens used by the collation rules
	    /// </summary>
	    ///
	    internal class TokenListHeader {
	        public TokenListHeader() {
	            this.m_pos_ = new int[IBM.ICU.Text.Collator.IDENTICAL + 1];
	            this.m_gapsLo_ = new int[3 * (IBM.ICU.Text.Collator.TERTIARY + 1)];
	            this.m_gapsHi_ = new int[3 * (IBM.ICU.Text.Collator.TERTIARY + 1)];
	            this.m_numStr_ = new int[3 * (IBM.ICU.Text.Collator.TERTIARY + 1)];
	            this.m_fStrToken_ = new CollationRuleParser.Token [IBM.ICU.Text.Collator.TERTIARY + 1];
	            this.m_lStrToken_ = new CollationRuleParser.Token [IBM.ICU.Text.Collator.TERTIARY + 1];
	        }
	
	        internal CollationRuleParser.Token  m_first_;
	
	        internal CollationRuleParser.Token  m_last_;
	
	        internal CollationRuleParser.Token  m_reset_;
	
	        internal bool m_indirect_;
	
	        internal int m_baseCE_;
	
	        internal int m_baseContCE_;
	
	        internal int m_nextCE_;
	
	        internal int m_nextContCE_;
	
	        internal int m_previousCE_;
	
	        internal int m_previousContCE_;
	
	        internal int[] m_pos_;
	
	        internal int[] m_gapsLo_;
	
	        internal int[] m_gapsHi_;
	
	        internal int[] m_numStr_;
	
	        internal CollationRuleParser.Token [] m_fStrToken_;
	
	        internal CollationRuleParser.Token [] m_lStrToken_;
	    }
	
	    /// <summary>
	    /// Token wrapper for collation rules
	    /// </summary>
	    ///
	    internal class Token {
	        // package private data members ---------------------------------------
	
	        internal int[] m_CE_;
	
	        internal int m_CELength_;
	
	        internal int[] m_expCE_;
	
	        internal int m_expCELength_;
	
	        internal int m_source_;
	
	        internal int m_expansion_;
	
	        internal int m_prefix_;
	
	        internal int m_strength_;
	
	        internal int m_toInsert_;
	
	        internal int m_polarity_; // 1 for <, <<, <<<, , ; and 0 for >, >>, >>>
	
	        internal CollationRuleParser.TokenListHeader  m_listHeader_;
	
	        internal CollationRuleParser.Token  m_previous_;
	
	        internal CollationRuleParser.Token  m_next_;
	
	        internal StringBuilder m_rules_;
	
	        internal char m_flags_;
	
	        // package private constructors ---------------------------------------
	
	        internal Token() {
	            m_CE_ = new int[128];
	            m_expCE_ = new int[128];
	            // TODO: this should also handle reverse
	            m_polarity_ = IBM.ICU.Text.CollationRuleParser.TOKEN_POLARITY_POSITIVE_;
	            m_next_ = null;
	            m_previous_ = null;
	            m_CELength_ = 0;
	            m_expCELength_ = 0;
	        }
	
	        // package private methods --------------------------------------------
	
	        /// <summary>
	        /// Hashcode calculation for token
	        /// </summary>
	        ///
	        /// <returns>the hashcode</returns>
	        public override int GetHashCode() {
	            int result = 0;
	            int len = (int) (((uint) (m_source_ & -16777216)) >> 24);
	            int inc = ((len - 32) / 32) + 1;
	
	            int start = m_source_ & 0x00FFFFFF;
	            int limit = start + len;
	
	            while (start < limit) {
	                result = (result * 37) + m_rules_[start];
	                start += inc;
	            }
	            return result;
	        }
	
	        /// <summary>
	        /// Equals calculation
	        /// </summary>
	        ///
	        /// <param name="target">object to compare</param>
	        /// <returns>true if target is the same as this object</returns>
	        public override bool Equals(Object target) {
	            if (target == (Object) this) {
	                return true;
	            }
	            if (target  is  CollationRuleParser.Token ) {
	                CollationRuleParser.Token  t = (CollationRuleParser.Token ) target;
	                int sstart = m_source_ & 0x00FFFFFF;
	                int tstart = t.m_source_ & 0x00FFFFFF;
	                int slimit = (m_source_ & -16777216) >> 24;
	                int tlimit = (m_source_ & -16777216) >> 24;
	
	                int end = sstart + slimit - 1;
	
	                if (m_source_ == 0 || t.m_source_ == 0) {
	                    return false;
	                }
	                if (slimit != tlimit) {
	                    return false;
	                }
	                if (m_source_ == t.m_source_) {
	                    return true;
	                }
	
	                while (sstart < end
	                        && m_rules_[sstart] == t.m_rules_[tstart]) {
	                    ++sstart;
	                    ++tstart;
	                }
	                if (m_rules_[sstart] == t.m_rules_[tstart]) {
	                    return true;
	                }
	            }
	            return false;
	        }
	    }
	
	    // package private data member -------------------------------------------
	
	    /// <summary>
	    /// Indicator that the token is resetted yet, ie & in the rules
	    /// </summary>
	    ///
	    internal const int TOKEN_RESET_ = -559038737;
	
	    /// <summary>
	    /// Size of the number of tokens
	    /// </summary>
	    ///
	    internal int m_resultLength_;
	
	    /// <summary>
	    /// List of parsed tokens
	    /// </summary>
	    ///
	    internal CollationRuleParser.TokenListHeader [] m_listHeader_;
	
	    /// <summary>
	    /// Variable top token
	    /// </summary>
	    ///
	    internal CollationRuleParser.Token  m_variableTop_;
	
	    /// <summary>
	    /// Collation options
	    /// </summary>
	    ///
	    internal CollationRuleParser.OptionSet  m_options_;
	
	    /// <summary>
	    /// Normalized collation rules with some extra characters
	    /// </summary>
	    ///
	    internal StringBuilder m_source_;
	
	    /// <summary>
	    /// Hash table to keep all tokens
	    /// </summary>
	    ///
	    internal Hashtable m_hashTable_;
	
	    // package private method ------------------------------------------------
	
	    internal void SetDefaultOptionsInCollator(RuleBasedCollator collator) {
	        collator.m_defaultStrength_ = m_options_.m_strength_;
	        collator.m_defaultDecomposition_ = m_options_.m_decomposition_;
	        collator.m_defaultIsFrenchCollation_ = m_options_.m_isFrenchCollation_;
	        collator.m_defaultIsAlternateHandlingShifted_ = m_options_.m_isAlternateHandlingShifted_;
	        collator.m_defaultIsCaseLevel_ = m_options_.m_isCaseLevel_;
	        collator.m_defaultCaseFirst_ = m_options_.m_caseFirst_;
	        collator.m_defaultIsHiragana4_ = m_options_.m_isHiragana4_;
	        collator.m_defaultVariableTopValue_ = m_options_.m_variableTopValue_;
	    }
	
	    // private inner classes -------------------------------------------------
	
	    /// <summary>
	    /// This is a token that has been parsed but not yet processed. Used to
	    /// reduce the number of arguments in the parser
	    /// </summary>
	    ///
	    private class ParsedToken {
	        // private constructor ----------------------------------------------
	
	        /// <summary>
	        /// Empty constructor
	        /// </summary>
	        ///
	        internal ParsedToken() {
	            m_charsLen_ = 0;
	            m_charsOffset_ = 0;
	            m_extensionLen_ = 0;
	            m_extensionOffset_ = 0;
	            m_prefixLen_ = 0;
	            m_prefixOffset_ = 0;
	            m_flags_ = ((Char)0);
	            m_strength_ = IBM.ICU.Text.CollationRuleParser.TOKEN_UNSET_;
	        }
	
	        // private data members ---------------------------------------------
	
	        internal int m_strength_;
	
	        internal int m_charsOffset_;
	
	        internal int m_charsLen_;
	
	        internal int m_extensionOffset_;
	
	        internal int m_extensionLen_;
	
	        internal int m_prefixOffset_;
	
	        internal int m_prefixLen_;
	
	        internal char m_flags_;
	
	        internal char m_indirectIndex_;
	    }
	
	    /// <summary>
	    /// Boundary wrappers
	    /// </summary>
	    ///
	    private class IndirectBoundaries {
	        // package private constructor ---------------------------------------
	
	        internal IndirectBoundaries(int[] startce, int[] limitce) {
	            // Set values for the top - TODO: once we have values for all the
	            // indirects, we are going to initalize here.
	            m_startCE_ = startce[0];
	            m_startContCE_ = startce[1];
	            if (limitce != null) {
	                m_limitCE_ = limitce[0];
	                m_limitContCE_ = limitce[1];
	            } else {
	                m_limitCE_ = 0;
	                m_limitContCE_ = 0;
	            }
	        }
	
	        // package private data members --------------------------------------
	
	        internal int m_startCE_;
	
	        internal int m_startContCE_;
	
	        internal int m_limitCE_;
	
	        internal int m_limitContCE_;
	    }
	
	    /// <summary>
	    /// Collation option rule tag
	    /// </summary>
	    ///
	    private class TokenOption {
	        // package private constructor ---------------------------------------
	
	        internal TokenOption(String name, int attribute, String[] suboptions,
	                int[] suboptionattributevalue) {
	            m_name_ = name;
	            m_attribute_ = attribute;
	            m_subOptions_ = suboptions;
	            m_subOptionAttributeValues_ = suboptionattributevalue;
	        }
	
	        // package private data member ---------------------------------------
	
	        public String m_name_;

            public int m_attribute_;

            public String[] m_subOptions_;

            public int[] m_subOptionAttributeValues_;
	    }
	
	    // private variables -----------------------------------------------------
	
	    /// <summary>
	    /// Current parsed token
	    /// </summary>
	    ///
	    private CollationRuleParser.ParsedToken  m_parsedToken_;
	
	    /// <summary>
	    /// Collation rule
	    /// </summary>
	    ///
	    private String m_rules_;
	
	    private int m_current_;
	
	    /// <summary>
	    /// End of the option while reading. Need it for UnicodeSet reading support.
	    /// </summary>
	    ///
	    private int m_optionEnd_;
	
	    /*
	     * Current offset in m_source
	     */
	    // private int m_sourceLimit_;
	    /// <summary>
	    /// Offset to m_source_ ofr the extra expansion characters
	    /// </summary>
	    ///
	    private int m_extraCurrent_;
	
	    /// <summary>
	    /// UnicodeSet that contains code points to be copied from the UCA
	    /// </summary>
	    ///
	    internal UnicodeSet m_copySet_;
	
	    /// <summary>
	    /// UnicodeSet that contains code points for which we want to remove UCA
	    /// contractions. It implies copying of these code points from the UCA.
	    /// </summary>
	    ///
	    internal UnicodeSet m_removeSet_;
	
	    /*
	     * This is space for the extra strings that need to be unquoted during the
	     * parsing of the rules
	     */
	    // private static final int TOKEN_EXTRA_RULE_SPACE_SIZE_ = 2048;
	    /// <summary>
	    /// Indicator that the token is not set yet
	    /// </summary>
	    ///
	    private const int TOKEN_UNSET_ = -1;
	
	    /*
	     * Indicator that the rule is in the > polarity, ie everything on the right
	     * of the rule is less than
	     */
	    // private static final int TOKEN_POLARITY_NEGATIVE_ = 0;
	    /// <summary>
	    /// Indicator that the rule is in the < polarity, ie everything on the right
	    /// of the rule is greater than
	    /// </summary>
	    ///
	    private const int TOKEN_POLARITY_POSITIVE_ = 1;
	
	    /// <summary>
	    /// Flag mask to determine if top is set
	    /// </summary>
	    ///
	    private const int TOKEN_TOP_MASK_ = 0x04;
	
	    /// <summary>
	    /// Flag mask to determine if variable top is set
	    /// </summary>
	    ///
	    private const int TOKEN_VARIABLE_TOP_MASK_ = 0x08;
	
	    /// <summary>
	    /// Flag mask to determine if a before attribute is set
	    /// </summary>
	    ///
	    private const int TOKEN_BEFORE_ = 0x03;
	
	    /// <summary>
	    /// For use in parsing token options
	    /// </summary>
	    ///
	    private const int TOKEN_SUCCESS_MASK_ = 0x10;
	
	    /// <summary>
	    /// These values are used for finding CE values for indirect positioning. Indirect positioning is a mechanism for allowing resets on symbolic values. It only works for resets and you cannot tailor indirect names. An indirect name can define either an anchor point or a range. An anchor point behaves in exactly the same way as a code point in reset would, except that it cannot be tailored. A range (we currently only know for the [top] range will explicitly set the upper bound for generated CEs, thus allowing for better control over how many CEs can be squeezed between in the range without performance penalty. In that respect, we use [top] for tailoring of locales that use CJK characters. Other indirect values are currently a pure convenience, they can be used to assure that the CEs will be always positioned in the same place relative to a point with known properties (e.g. first primary ignorable).
	    /// </summary>
	    ///
	    private static readonly CollationRuleParser.IndirectBoundaries [] INDIRECT_BOUNDARIES_;
	
	    // /**
	    // * Inverse UCA constants
	    // */
	    // private static final int INVERSE_SIZE_MASK_ = 0xFFF00000;
	    // private static final int INVERSE_OFFSET_MASK_ = 0x000FFFFF;
	    // private static final int INVERSE_SHIFT_VALUE_ = 20;
	
	    /// <summary>
	    /// Collation option tags [last variable] last variable value [last primary ignorable] largest CE for primary ignorable [last secondary ignorable] largest CE for secondary ignorable [last tertiary ignorable] largest CE for tertiary ignorable [top] guaranteed to be above all implicit CEs, for now and in the future (in 1.8)
	    /// </summary>
	    ///
	    private static readonly CollationRuleParser.TokenOption [] RULES_OPTIONS_;
	
	    /// <summary>
	    /// Utility data members
	    /// </summary>
	    ///
	    private CollationRuleParser.Token  m_utilToken_;
	
	    private CollationElementIterator m_UCAColEIter_;
	
	    private int[] m_utilCEBuffer_;
	
	    // private methods -------------------------------------------------------
	
	    /// <summary>
	    /// Assembles the token list
	    /// </summary>
	    ///
	    /// <exception cref="ParseException">thrown when rules syntax fails</exception>
	    internal int AssembleTokenList() {
	        CollationRuleParser.Token  lastToken = null;
	        m_parsedToken_.m_strength_ = TOKEN_UNSET_;
	        int sourcelimit = m_source_.Length;
	        int expandNext = 0;
	
	        while (m_current_ < sourcelimit) {
	            m_parsedToken_.m_prefixOffset_ = 0;
	            if (ParseNextToken(lastToken == null) < 0) {
	                // we have reached the end
	                continue;
	            }
	            char specs = m_parsedToken_.m_flags_;
	            bool variableTop = ((specs & TOKEN_VARIABLE_TOP_MASK_) != 0);
	            bool top = ((specs & TOKEN_TOP_MASK_) != 0);
	            int lastStrength = TOKEN_UNSET_;
	            if (lastToken != null) {
	                lastStrength = lastToken.m_strength_;
	            }
	            m_utilToken_.m_source_ = m_parsedToken_.m_charsLen_ << 24
	                    | m_parsedToken_.m_charsOffset_;
	            m_utilToken_.m_rules_ = m_source_;
	            // 4 Lookup each source in the CharsToToken map, and find a
	            // sourcetoken
	            CollationRuleParser.Token  sourceToken = (CollationRuleParser.Token ) m_hashTable_[m_utilToken_];
	            if (m_parsedToken_.m_strength_ != TOKEN_RESET_) {
	                if (lastToken == null) {
	                    // this means that rules haven't started properly
	                    ThrowParseException(m_source_.ToString(), 0);
	                }
	                // 6 Otherwise (when relation != reset)
	                if (sourceToken == null) {
	                    // If sourceToken is null, create new one
	                    sourceToken = new CollationRuleParser.Token ();
	                    sourceToken.m_rules_ = m_source_;
	                    sourceToken.m_source_ = m_parsedToken_.m_charsLen_ << 24
	                            | m_parsedToken_.m_charsOffset_;
	                    sourceToken.m_prefix_ = m_parsedToken_.m_prefixLen_ << 24
	                            | m_parsedToken_.m_prefixOffset_;
	                    // TODO: this should also handle reverse
	                    sourceToken.m_polarity_ = TOKEN_POLARITY_POSITIVE_;
	                    sourceToken.m_next_ = null;
	                    sourceToken.m_previous_ = null;
	                    sourceToken.m_CELength_ = 0;
	                    sourceToken.m_expCELength_ = 0;
	                    ILOG.J2CsMapping.Collections.Collections.Put(m_hashTable_,sourceToken,sourceToken);
	                } else {
	                    // we could have fished out a reset here
	                    if (sourceToken.m_strength_ != TOKEN_RESET_
	                            && lastToken != sourceToken) {
	                        // otherwise remove sourceToken from where it was.
	                        if (sourceToken.m_next_ != null) {
	                            if (sourceToken.m_next_.m_strength_ > sourceToken.m_strength_) {
	                                sourceToken.m_next_.m_strength_ = sourceToken.m_strength_;
	                            }
	                            sourceToken.m_next_.m_previous_ = sourceToken.m_previous_;
	                        } else {
	                            sourceToken.m_listHeader_.m_last_ = sourceToken.m_previous_;
	                        }
	                        if (sourceToken.m_previous_ != null) {
	                            sourceToken.m_previous_.m_next_ = sourceToken.m_next_;
	                        } else {
	                            sourceToken.m_listHeader_.m_first_ = sourceToken.m_next_;
	                        }
	                        sourceToken.m_next_ = null;
	                        sourceToken.m_previous_ = null;
	                    }
	                }
	                sourceToken.m_strength_ = m_parsedToken_.m_strength_;
	                sourceToken.m_listHeader_ = lastToken.m_listHeader_;
	
	                // 1. Find the strongest strength in each list, and set
	                // strongestP and strongestN accordingly in the headers.
	                if (lastStrength == TOKEN_RESET_
	                        || sourceToken.m_listHeader_.m_first_ == null) {
	                    // If LAST is a reset insert sourceToken in the list.
	                    if (sourceToken.m_listHeader_.m_first_ == null) {
	                        sourceToken.m_listHeader_.m_first_ = sourceToken;
	                        sourceToken.m_listHeader_.m_last_ = sourceToken;
	                    } else { // we need to find a place for us
	                             // and we'll get in front of the same strength
	                        if (sourceToken.m_listHeader_.m_first_.m_strength_ <= sourceToken.m_strength_) {
	                            sourceToken.m_next_ = sourceToken.m_listHeader_.m_first_;
	                            sourceToken.m_next_.m_previous_ = sourceToken;
	                            sourceToken.m_listHeader_.m_first_ = sourceToken;
	                            sourceToken.m_previous_ = null;
	                        } else {
	                            lastToken = sourceToken.m_listHeader_.m_first_;
	                            while (lastToken.m_next_ != null
	                                    && lastToken.m_next_.m_strength_ > sourceToken.m_strength_) {
	                                lastToken = lastToken.m_next_;
	                            }
	                            if (lastToken.m_next_ != null) {
	                                lastToken.m_next_.m_previous_ = sourceToken;
	                            } else {
	                                sourceToken.m_listHeader_.m_last_ = sourceToken;
	                            }
	                            sourceToken.m_previous_ = lastToken;
	                            sourceToken.m_next_ = lastToken.m_next_;
	                            lastToken.m_next_ = sourceToken;
	                        }
	                    }
	                } else {
	                    // Otherwise (when LAST is not a reset)
	                    // if polarity (LAST) == polarity(relation), insert
	                    // sourceToken after LAST, otherwise insert before.
	                    // when inserting after or before, search to the next
	                    // position with the same strength in that direction.
	                    // (This is called postpone insertion).
	                    if (sourceToken != lastToken) {
	                        if (lastToken.m_polarity_ == sourceToken.m_polarity_) {
	                            while (lastToken.m_next_ != null
	                                    && lastToken.m_next_.m_strength_ > sourceToken.m_strength_) {
	                                lastToken = lastToken.m_next_;
	                            }
	                            sourceToken.m_previous_ = lastToken;
	                            if (lastToken.m_next_ != null) {
	                                lastToken.m_next_.m_previous_ = sourceToken;
	                            } else {
	                                sourceToken.m_listHeader_.m_last_ = sourceToken;
	                            }
	                            sourceToken.m_next_ = lastToken.m_next_;
	                            lastToken.m_next_ = sourceToken;
	                        } else {
	                            while (lastToken.m_previous_ != null
	                                    && lastToken.m_previous_.m_strength_ > sourceToken.m_strength_) {
	                                lastToken = lastToken.m_previous_;
	                            }
	                            sourceToken.m_next_ = lastToken;
	                            if (lastToken.m_previous_ != null) {
	                                lastToken.m_previous_.m_next_ = sourceToken;
	                            } else {
	                                sourceToken.m_listHeader_.m_first_ = sourceToken;
	                            }
	                            sourceToken.m_previous_ = lastToken.m_previous_;
	                            lastToken.m_previous_ = sourceToken;
	                        }
	                    } else { // repeated one thing twice in rules, stay with the
	                             // stronger strength
	                        if (lastStrength < sourceToken.m_strength_) {
	                            sourceToken.m_strength_ = lastStrength;
	                        }
	                    }
	                }
	                // if the token was a variable top, we're gonna put it in
	                if (variableTop == true && m_variableTop_ == null) {
	                    variableTop = false;
	                    m_variableTop_ = sourceToken;
	                }
	                // Treat the expansions.
	                // There are two types of expansions: explicit (x / y) and
	                // reset based propagating expansions
	                // (&abc * d * e <=> &ab * d / c * e / c)
	                // if both of them are in effect for a token, they are combined.
	                sourceToken.m_expansion_ = m_parsedToken_.m_extensionLen_ << 24
	                        | m_parsedToken_.m_extensionOffset_;
	                if (expandNext != 0) {
	                    if (sourceToken.m_strength_ == IBM.ICU.Text.Collator.PRIMARY) {
	                        // primary strength kills off the implicit expansion
	                        expandNext = 0;
	                    } else if (sourceToken.m_expansion_ == 0) {
	                        // if there is no expansion, implicit is just added to
	                        // the token
	                        sourceToken.m_expansion_ = expandNext;
	                    } else {
	                        // there is both explicit and implicit expansion.
	                        // We need to make a combination
	                        int start = expandNext & 0xFFFFFF;
	                        int size = (int) (((uint) expandNext) >> 24);
	                        if (size > 0) {
	                            m_source_.Append(m_source_.ToString(start,start
	                                                                + size-start));
	                        }
	                        start = m_parsedToken_.m_extensionOffset_;
	                        m_source_.Append(m_source_.ToString(start,start
	                                                        + m_parsedToken_.m_extensionLen_-start));
	                        sourceToken.m_expansion_ = (size + m_parsedToken_.m_extensionLen_) << 24
	                                | m_extraCurrent_;
	                        m_extraCurrent_ += size
	                                + m_parsedToken_.m_extensionLen_;
	                    }
	                }
	                // if the previous token was a reset before, the strength of
	                // this
	                // token must match the strength of before. Otherwise we have an
	                // undefined situation.
	                // In other words, we currently have a cludge which we use to
	                // represent &a >> x. This is written as &[before 2]a << x.
	                if ((lastToken.m_flags_ & TOKEN_BEFORE_) != 0) {
	                    int beforeStrength = (lastToken.m_flags_ & TOKEN_BEFORE_) - 1;
	                    if (beforeStrength != sourceToken.m_strength_) {
	                        ThrowParseException(m_source_.ToString(), m_current_);
	                    }
	                }
	
	            } else {
	                if (lastToken != null && lastStrength == TOKEN_RESET_) {
	                    // if the previous token was also a reset, this means that
	                    // we have two consecutive resets and we want to remove the
	                    // previous one if empty
	                    if (m_resultLength_ > 0
	                            && m_listHeader_[m_resultLength_ - 1].m_first_ == null) {
	                        m_resultLength_--;
	                    }
	                }
	                if (sourceToken == null) {
	                    // this is a reset, but it might still be somewhere in the
	                    // tailoring, in shorter form
	                    int searchCharsLen = m_parsedToken_.m_charsLen_;
	                    while (searchCharsLen > 1 && sourceToken == null) {
	                        searchCharsLen--;
	                        // key = searchCharsLen << 24 | charsOffset;
	                        m_utilToken_.m_source_ = searchCharsLen << 24
	                                | m_parsedToken_.m_charsOffset_;
	                        m_utilToken_.m_rules_ = m_source_;
	                        sourceToken = (CollationRuleParser.Token ) m_hashTable_[m_utilToken_];
	                    }
	                    if (sourceToken != null) {
	                        expandNext = (m_parsedToken_.m_charsLen_ - searchCharsLen) << 24
	                                | (m_parsedToken_.m_charsOffset_ + searchCharsLen);
	                    }
	                }
	                if ((specs & TOKEN_BEFORE_) != 0) {
	                    if (top == false) {
	                        // we're doing before & there is no indirection
	                        int strength = (specs & TOKEN_BEFORE_) - 1;
	                        if (sourceToken != null
	                                && sourceToken.m_strength_ != TOKEN_RESET_) {
	                            // this is a before that is already ordered in the
	                            // UCA
	                            // - so we need to get the previous with good
	                            // strength
	                            while (sourceToken.m_strength_ > strength
	                                    && sourceToken.m_previous_ != null) {
	                                sourceToken = sourceToken.m_previous_;
	                            }
	                            // here, either we hit the strength or NULL
	                            if (sourceToken.m_strength_ == strength) {
	                                if (sourceToken.m_previous_ != null) {
	                                    sourceToken = sourceToken.m_previous_;
	                                } else { // start of list
	                                    sourceToken = sourceToken.m_listHeader_.m_reset_;
	                                }
	                            } else { // we hit NULL, we should be doing the else
	                                     // part
	                                sourceToken = sourceToken.m_listHeader_.m_reset_;
	                                sourceToken = GetVirginBefore(sourceToken,
	                                        strength);
	                            }
	                        } else {
	                            sourceToken = GetVirginBefore(sourceToken, strength);
	                        }
	                    } else {
	                        // this is both before and indirection
	                        top = false;
	                        m_listHeader_[m_resultLength_] = new CollationRuleParser.TokenListHeader ();
	                        m_listHeader_[m_resultLength_].m_previousCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_previousContCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_indirect_ = true;
	                        // we need to do slightly more work. we need to get the
	                        // baseCE using the inverse UCA & getPrevious. The next
	                        // bound is not set, and will be decided in ucol_bld
	                        int strength_0 = (specs & TOKEN_BEFORE_) - 1;
	                        int baseCE = INDIRECT_BOUNDARIES_[m_parsedToken_.m_indirectIndex_].m_startCE_;
	                        int baseContCE = INDIRECT_BOUNDARIES_[m_parsedToken_.m_indirectIndex_].m_startContCE_;
	                        int[] ce = new int[2];
	                        if (((int) (((uint) baseCE) >> 24) >= RuleBasedCollator.UCA_CONSTANTS_.PRIMARY_IMPLICIT_MIN_)
	                                && ((int) (((uint) baseCE) >> 24) <= RuleBasedCollator.UCA_CONSTANTS_.PRIMARY_IMPLICIT_MAX_)) { /*
	                                                                                                                 * implicits
	                                                                                                                 * -
	                                                                                                                 */
	                            int primary = baseCE
	                                    & IBM.ICU.Text.RuleBasedCollator.CE_PRIMARY_MASK_
	                                    | (baseContCE & IBM.ICU.Text.RuleBasedCollator.CE_PRIMARY_MASK_) >> 16;
	                            int raw = IBM.ICU.Text.RuleBasedCollator.impCEGen_
	                                    .GetRawFromImplicit(primary);
	                            int primaryCE = IBM.ICU.Text.RuleBasedCollator.impCEGen_
	                                    .GetImplicitFromRaw(raw - 1);
	                            ce[0] = primaryCE
	                                    & IBM.ICU.Text.RuleBasedCollator.CE_PRIMARY_MASK_
	                                    | 0x0505;
	                            ce[1] = (primaryCE << 16)
	                                    & IBM.ICU.Text.RuleBasedCollator.CE_PRIMARY_MASK_
	                                    | IBM.ICU.Text.RuleBasedCollator.CE_CONTINUATION_MARKER_;
	                        } else {
	                            CollationParsedRuleBuilder.InverseUCA invuca = IBM.ICU.Text.CollationParsedRuleBuilder.INVERSE_UCA_;
	                            invuca.GetInversePrevCE(baseCE, baseContCE,
	                                    strength_0, ce);
	                        }
	                        m_listHeader_[m_resultLength_].m_baseCE_ = ce[0];
	                        m_listHeader_[m_resultLength_].m_baseContCE_ = ce[1];
	                        m_listHeader_[m_resultLength_].m_nextCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_nextContCE_ = 0;
	
	                        sourceToken = new CollationRuleParser.Token ();
	                        expandNext = InitAReset(0, sourceToken);
	                    }
	                }
	                // 5 If the relation is a reset:
	                // If sourceToken is null
	                // Create new list, create new sourceToken, make the baseCE
	                // from source, put the sourceToken in ListHeader of the new
	                // list
	                if (sourceToken == null) {
	                    if (m_listHeader_[m_resultLength_] == null) {
	                        m_listHeader_[m_resultLength_] = new CollationRuleParser.TokenListHeader ();
	                    }
	                    // 3 Consider each item: relation, source, and expansion:
	                    // e.g. ...< x / y ...
	                    // First convert all expansions into normal form.
	                    // Examples:
	                    // If "xy" doesn't occur earlier in the list or in the UCA,
	                    // convert &xy * c * d * ... into &x * c/y * d * ...
	                    // Note: reset values can never have expansions, although
	                    // they can cause the very next item to have one. They may
	                    // be contractions, if they are found earlier in the list.
	                    if (top == false) {
	                        CollationElementIterator coleiter = IBM.ICU.Text.RuleBasedCollator.UCA_
	                                .GetCollationElementIterator(m_source_.ToString(m_parsedToken_.m_charsOffset_,m_parsedToken_.m_charsOffset_
	                                                                                        + m_parsedToken_.m_charsLen_-m_parsedToken_.m_charsOffset_));
	
	                        int CE = coleiter.Next();
	                        // offset to the character in the full rule string
	                        int expand = coleiter.GetOffset()
	                                + m_parsedToken_.m_charsOffset_;
	                        int SecondCE = coleiter.Next();
	
	                        m_listHeader_[m_resultLength_].m_baseCE_ = CE & -193;
	                        if (IBM.ICU.Text.RuleBasedCollator.IsContinuation(SecondCE)) {
	                            m_listHeader_[m_resultLength_].m_baseContCE_ = SecondCE;
	                        } else {
	                            m_listHeader_[m_resultLength_].m_baseContCE_ = 0;
	                        }
	                        m_listHeader_[m_resultLength_].m_nextCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_nextContCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_previousCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_previousContCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_indirect_ = false;
	                        sourceToken = new CollationRuleParser.Token ();
	                        expandNext = InitAReset(expand, sourceToken);
	                    } else { // top == TRUE
	                        top = false;
	                        m_listHeader_[m_resultLength_].m_previousCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_previousContCE_ = 0;
	                        m_listHeader_[m_resultLength_].m_indirect_ = true;
	                        CollationRuleParser.IndirectBoundaries  ib = INDIRECT_BOUNDARIES_[m_parsedToken_.m_indirectIndex_];
	                        m_listHeader_[m_resultLength_].m_baseCE_ = ib.m_startCE_;
	                        m_listHeader_[m_resultLength_].m_baseContCE_ = ib.m_startContCE_;
	                        m_listHeader_[m_resultLength_].m_nextCE_ = ib.m_limitCE_;
	                        m_listHeader_[m_resultLength_].m_nextContCE_ = ib.m_limitContCE_;
	                        sourceToken = new CollationRuleParser.Token ();
	                        expandNext = InitAReset(0, sourceToken);
	                    }
	                } else { // reset to something already in rules
	                    top = false;
	                }
	            }
	            // 7 After all this, set LAST to point to sourceToken, and goto
	            // step 3.
	            lastToken = sourceToken;
	        }
	
	        if (m_resultLength_ > 0
	                && m_listHeader_[m_resultLength_ - 1].m_first_ == null) {
	            m_resultLength_--;
	        }
	        return m_resultLength_;
	    }
	
	    /// <summary>
	    /// Formats and throws a ParseException
	    /// </summary>
	    ///
	    /// <param name="rules">collation rule that failed</param>
	    /// <param name="offset">failed offset in rules</param>
	    /// <exception cref="ParseException">with failure information</exception>
	    private static void ThrowParseException(String rules, int offset) {
	        // for pre-context
	        String precontext = rules.Substring(0,(offset)-(0));
	        String postcontext = rules.Substring(offset,(rules.Length)-(offset));
	        StringBuilder error = new StringBuilder(
	                "Parse error occurred in rule at offset ");
	        error.Append(offset);
	        error.Append("\n after the prefix \"");
	        error.Append(precontext);
	        error.Append("\" before the suffix \"");
	        error.Append(postcontext);
	        throw new ILOG.J2CsMapping.Util.ParseException(error.ToString()+offset);
	    }
	
	    private bool DoSetTop() {
	        m_parsedToken_.m_charsOffset_ = m_extraCurrent_;
	        m_source_.Append((char) 0xFFFE);
	        CollationRuleParser.IndirectBoundaries  ib = INDIRECT_BOUNDARIES_[m_parsedToken_.m_indirectIndex_];
	        m_source_.Append((char) (ib.m_startCE_ >> 16));
	        m_source_.Append((char) (ib.m_startCE_ & 0xFFFF));
	        m_extraCurrent_ += 3;
	        if (INDIRECT_BOUNDARIES_[m_parsedToken_.m_indirectIndex_].m_startContCE_ == 0) {
	            m_parsedToken_.m_charsLen_ = 3;
	        } else {
	            m_source_
	                    .Append((char) (INDIRECT_BOUNDARIES_[m_parsedToken_.m_indirectIndex_].m_startContCE_ >> 16));
	            m_source_
	                    .Append((char) (INDIRECT_BOUNDARIES_[m_parsedToken_.m_indirectIndex_].m_startContCE_ & 0xFFFF));
	            m_extraCurrent_ += 2;
	            m_parsedToken_.m_charsLen_ = 5;
	        }
	        return true;
	    }
	
	    private static bool IsCharNewLine(char c) {
	        switch ((int) c) {
	        case 0x000A: /* LF */
	        case 0x000D: /* CR */
	        case 0x000C: /* FF */
	        case 0x0085: /* NEL */
	        case 0x2028: /* LS */
	        case 0x2029: /* PS */
	            return true;
	        default:
	            return false;
	        }
	    }
	
	    /// <summary>
	    /// Getting the next token
	    /// </summary>
	    ///
	    /// <param name="startofrules">flag indicating if we are at the start of rules</param>
	    /// <returns>the offset of the rules</returns>
	    /// <exception cref="ParseException">thrown when rule parsing fails</exception>
	    private int ParseNextToken(bool startofrules) {
	        // parsing part
	        bool variabletop = false;
	        bool top = false;
	        bool inchars = true;
	        bool inquote = false;
	        bool wasinquote = false;
	        byte before = 0;
	        bool isescaped = false;
	        int /* newcharslen = 0, */newextensionlen = 0;
	        int /* charsoffset = 0, */extensionoffset = 0;
	        int newstrength = TOKEN_UNSET_;
	
	        m_parsedToken_.m_charsLen_ = 0;
	        m_parsedToken_.m_charsOffset_ = 0;
	        m_parsedToken_.m_prefixOffset_ = 0;
	        m_parsedToken_.m_prefixLen_ = 0;
	        m_parsedToken_.m_indirectIndex_ = ((Char)0);
	
	        int limit = m_rules_.Length;
	        while (m_current_ < limit) {
	            char ch = m_source_[m_current_];
	            if (inquote) {
	                if (ch == 0x0027) { // '\''
	                    inquote = false;
	                } else {
	                    if ((m_parsedToken_.m_charsLen_ == 0) || inchars) {
	                        if (m_parsedToken_.m_charsLen_ == 0) {
	                            m_parsedToken_.m_charsOffset_ = m_extraCurrent_;
	                        }
	                        m_parsedToken_.m_charsLen_++;
	                    } else {
	                        if (newextensionlen == 0) {
	                            extensionoffset = m_extraCurrent_;
	                        }
	                        newextensionlen++;
	                    }
	                }
	            } else if (isescaped) {
	                isescaped = false;
	                if (newstrength == TOKEN_UNSET_) {
	                    ThrowParseException(m_rules_, m_current_);
	                }
	                if (ch != 0 && m_current_ != limit) {
	                    if (inchars) {
	                        if (m_parsedToken_.m_charsLen_ == 0) {
	                            m_parsedToken_.m_charsOffset_ = m_current_;
	                        }
	                        m_parsedToken_.m_charsLen_++;
	                    } else {
	                        if (newextensionlen == 0) {
	                            extensionoffset = m_current_;
	                        }
	                        newextensionlen++;
	                    }
	                }
	            } else {
	                if (!IBM.ICU.Impl.UCharacterProperty.IsRuleWhiteSpace(ch)) {
	                    // Sets the strength for this entry
	                    switch ((int) ch) {
	                    case 0x003D: // '='
	                        if (newstrength != TOKEN_UNSET_) {
	                            return DoEndParseNextToken(newstrength, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        // if we start with strength, we'll reset to top
	                        if (startofrules == true) {
	                            m_parsedToken_.m_indirectIndex_ = ((Char)5);
	                            top = DoSetTop();
	                            return DoEndParseNextToken(TOKEN_RESET_, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        newstrength = IBM.ICU.Text.Collator.IDENTICAL;
	                        break;
	                    case 0x002C: // ','
	                        if (newstrength != TOKEN_UNSET_) {
	                            return DoEndParseNextToken(newstrength, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        // if we start with strength, we'll reset to top
	                        if (startofrules == true) {
	                            m_parsedToken_.m_indirectIndex_ = ((Char)5);
	                            top = DoSetTop();
	                            return DoEndParseNextToken(TOKEN_RESET_, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        newstrength = IBM.ICU.Text.Collator.TERTIARY;
	                        break;
	                    case 0x003B: // ';'
	                        if (newstrength != TOKEN_UNSET_) {
	                            return DoEndParseNextToken(newstrength, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        // if we start with strength, we'll reset to top
	                        if (startofrules == true) {
	                            m_parsedToken_.m_indirectIndex_ = ((Char)5);
	                            top = DoSetTop();
	                            return DoEndParseNextToken(TOKEN_RESET_, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        newstrength = IBM.ICU.Text.Collator.SECONDARY;
	                        break;
	                    case 0x003C: // '<'
	                        if (newstrength != TOKEN_UNSET_) {
	                            return DoEndParseNextToken(newstrength, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        // if we start with strength, we'll reset to top
	                        if (startofrules == true) {
	                            m_parsedToken_.m_indirectIndex_ = ((Char)5);
	                            top = DoSetTop();
	                            return DoEndParseNextToken(TOKEN_RESET_, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        // before this, do a scan to verify whether this is
	                        // another strength
	                        if (m_source_[m_current_ + 1] == 0x003C) {
	                            m_current_++;
	                            if (m_source_[m_current_ + 1] == 0x003C) {
	                                m_current_++; // three in a row!
	                                newstrength = IBM.ICU.Text.Collator.TERTIARY;
	                            } else { // two in a row
	                                newstrength = IBM.ICU.Text.Collator.SECONDARY;
	                            }
	                        } else { // just one
	                            newstrength = IBM.ICU.Text.Collator.PRIMARY;
	                        }
	                        break;
	                    case 0x0026: // '&'
	                        if (newstrength != TOKEN_UNSET_) {
	                            return DoEndParseNextToken(newstrength, top,
	                                    extensionoffset, newextensionlen,
	                                    variabletop, before);
	                        }
	                        newstrength = TOKEN_RESET_; // PatternEntry::RESET = 0
	                        break;
	                    case 0x005b: // '['
	                        // options - read an option, analyze it
	                        m_optionEnd_ = m_rules_.IndexOf((char) 0x005d, m_current_);
	                        if (m_optionEnd_ != -1) { // ']'
	                            byte result = ReadAndSetOption();
	                            m_current_ = m_optionEnd_;
	                            if ((result & TOKEN_TOP_MASK_) != 0) {
	                                if (newstrength == TOKEN_RESET_) {
	                                    top = DoSetTop();
	                                    if (before != 0) {
	                                        // This is a combination of before and
	                                        // indirection like
	                                        // '&[before 2][first regular]<b'
	                                        m_source_.Append((char) 0x002d);
	                                        m_source_.Append((char) before);
	                                        m_extraCurrent_ += 2;
	                                        m_parsedToken_.m_charsLen_ += 2;
	                                    }
	                                    m_current_++;
	                                    return DoEndParseNextToken(newstrength,
	                                            true, extensionoffset,
	                                            newextensionlen, variabletop,
	                                            before);
	                                } else {
	                                    ThrowParseException(m_rules_, m_current_);
	                                }
	                            } else if ((result & TOKEN_VARIABLE_TOP_MASK_) != 0) {
	                                if (newstrength != TOKEN_RESET_
	                                        && newstrength != TOKEN_UNSET_) {
	                                    variabletop = true;
	                                    m_parsedToken_.m_charsOffset_ = m_extraCurrent_;
	                                    m_source_.Append((char) 0xFFFF);
	                                    m_extraCurrent_++;
	                                    m_current_++;
	                                    m_parsedToken_.m_charsLen_ = 1;
	                                    return DoEndParseNextToken(newstrength,
	                                            top, extensionoffset,
	                                            newextensionlen, variabletop,
	                                            before);
	                                } else {
	                                    ThrowParseException(m_rules_, m_current_);
	                                }
	                            } else if ((result & TOKEN_BEFORE_) != 0) {
	                                if (newstrength == TOKEN_RESET_) {
	                                    before = (byte) (result & TOKEN_BEFORE_);
	                                } else {
	                                    ThrowParseException(m_rules_, m_current_);
	                                }
	                            }
	                        }
	                        break;
	                    case 0x002F: // '/'
	                        wasinquote = false; // if we were copying source
	                                            // characters, we want to stop now
	                        inchars = false; // we're now processing expansion
	                        break;
	                    case 0x005C: // back slash for escaped chars
	                        isescaped = true;
	                        break;
	                    // found a quote, we're gonna start copying
	                    case 0x0027: // '\''
	                        if (newstrength == TOKEN_UNSET_) {
	                            // quote is illegal until we have a strength
	                            ThrowParseException(m_rules_, m_current_);
	                        }
	                        inquote = true;
	                        if (inchars) { // we're doing characters
	                            if (wasinquote == false) {
	                                m_parsedToken_.m_charsOffset_ = m_extraCurrent_;
	                            }
	                            if (m_parsedToken_.m_charsLen_ != 0) {
	                                m_source_.Append(m_source_.ToString(m_current_
	                                                                        - m_parsedToken_.m_charsLen_,m_current_-m_current_
	                                                                        - m_parsedToken_.m_charsLen_));
	                                m_extraCurrent_ += m_parsedToken_.m_charsLen_;
	                            }
	                            m_parsedToken_.m_charsLen_++;
	                        } else { // we're doing an expansion
	                            if (wasinquote == false) {
	                                extensionoffset = m_extraCurrent_;
	                            }
	                            if (newextensionlen != 0) {
	                                m_source_.Append(m_source_.ToString(m_current_
	                                                                        - newextensionlen,m_current_-m_current_
	                                                                        - newextensionlen));
	                                m_extraCurrent_ += newextensionlen;
	                            }
	                            newextensionlen++;
	                        }
	                        wasinquote = true;
	                        m_current_++;
	                        ch = m_source_[m_current_];
	                        if (ch == 0x0027) { // copy the double quote
	                            m_source_.Append(ch);
	                            m_extraCurrent_++;
	                            inquote = false;
	                        }
	                        break;
	                    // '@' is french only if the strength is not currently set
	                    // if it is, it's just a regular character in collation
	                    case 0x0040: // '@'
	                        if (newstrength == TOKEN_UNSET_) {
	                            m_options_.m_isFrenchCollation_ = true;
	                            break;
	                        }
	                        {
	                            m_parsedToken_.m_prefixOffset_ = m_parsedToken_.m_charsOffset_;
	                            m_parsedToken_.m_prefixLen_ = m_parsedToken_.m_charsLen_;
	                            if (inchars) {
	                                if (wasinquote == false) {
	                                    m_parsedToken_.m_charsOffset_ = m_extraCurrent_;
	                                }
	                                if (m_parsedToken_.m_charsLen_ != 0) {
	                                    String prefix = m_source_.ToString(m_current_
	                                                                                                - m_parsedToken_.m_charsLen_,m_current_-m_current_
	                                                                                                - m_parsedToken_.m_charsLen_);
	                                    m_source_.Append(prefix);
	                                    m_extraCurrent_ += m_parsedToken_.m_charsLen_;
	                                }
	                                m_parsedToken_.m_charsLen_++;
	                            }
	                            wasinquote = true;
	                            do {
	                                m_current_++;
	                                ch = m_source_[m_current_];
	                            } while (IBM.ICU.Impl.UCharacterProperty
	                                    .IsRuleWhiteSpace(ch));
	                            break;
	                        }
	                    break;
	                    case 0x007C: // |
	                        // this means we have actually been reading prefix part
	                        // we want to store read characters to the prefix part
	                        // and continue reading the characters (proper way
	                        // would be to restart reading the chars, but in that
	                        // case we would have to complicate the token hasher,
	                        // which I do not intend to play with. Instead, we will
	                        // do prefixes when prefixes are due (before adding the
	                        // elements).
	                        m_parsedToken_.m_prefixOffset_ = m_parsedToken_.m_charsOffset_;
	                        m_parsedToken_.m_prefixLen_ = m_parsedToken_.m_charsLen_;
	                        if (inchars) { // we're doing characters
	                            if (wasinquote == false) {
	                                m_parsedToken_.m_charsOffset_ = m_extraCurrent_;
	                            }
	                            if (m_parsedToken_.m_charsLen_ != 0) {
	                                String prefix_0 = m_source_.ToString(m_current_
	                                                                        - m_parsedToken_.m_charsLen_,m_current_-m_current_
	                                                                        - m_parsedToken_.m_charsLen_);
	                                m_source_.Append(prefix_0);
	                                m_extraCurrent_ += m_parsedToken_.m_charsLen_;
	                            }
	                            m_parsedToken_.m_charsLen_++;
	                        }
	                        wasinquote = true;
	                        do {
	                            m_current_++;
	                            ch = m_source_[m_current_];
	                            // skip whitespace between '|' and the character
	                        } while (IBM.ICU.Impl.UCharacterProperty.IsRuleWhiteSpace(ch));
	                        break;
	                    case 0x0023: // '#' // this is a comment, skip everything
	                                 // through the end of line
	                        do {
	                            m_current_++;
	                            ch = m_source_[m_current_];
	                        } while (!IsCharNewLine(ch));
	                        break;
	                    case 0x0021: // '!' // ignoring java set thai reordering
	                        break;
	                    default:
	                        if (newstrength == TOKEN_UNSET_) {
	                            ThrowParseException(m_rules_, m_current_);
	                        }
	                        if (IsSpecialChar(ch) && (inquote == false)) {
	                            ThrowParseException(m_rules_, m_current_);
	                        }
	                        if (ch == 0x0000 && m_current_ + 1 == limit) {
	                            break;
	                        }
	                        if (inchars) {
	                            if (m_parsedToken_.m_charsLen_ == 0) {
	                                m_parsedToken_.m_charsOffset_ = m_current_;
	                            }
	                            m_parsedToken_.m_charsLen_++;
	                        } else {
	                            if (newextensionlen == 0) {
	                                extensionoffset = m_current_;
	                            }
	                            newextensionlen++;
	                        }
	                        break;
	                    }
	                }
	            }
	            if (wasinquote) {
	                if (ch != 0x27) {
	                    m_source_.Append(ch);
	                    m_extraCurrent_++;
	                }
	            }
	            m_current_++;
	        }
	        return DoEndParseNextToken(newstrength, top, extensionoffset,
	                newextensionlen, variabletop, before);
	    }
	
	    /// <summary>
	    /// End the next parse token
	    /// </summary>
	    ///
	    /// <param name="newstrength">new strength</param>
	    /// <returns>offset in rules, -1 for end of rules</returns>
	    private int DoEndParseNextToken(int newstrength, /* int newcharslen, */
	    bool top, /* int charsoffset, */
	    int extensionoffset, int newextensionlen, bool variabletop, int before) {
	        if (newstrength == TOKEN_UNSET_) {
	            return -1;
	        }
	        if (m_parsedToken_.m_charsLen_ == 0 && top == false) {
	            ThrowParseException(m_rules_, m_current_);
	        }
	
	        m_parsedToken_.m_strength_ = newstrength;
	        // m_parsedToken_.m_charsOffset_ = charsoffset;
	        // m_parsedToken_.m_charsLen_ = newcharslen;
	        m_parsedToken_.m_extensionOffset_ = extensionoffset;
	        m_parsedToken_.m_extensionLen_ = newextensionlen;
	        m_parsedToken_.m_flags_ = (char) (((variabletop) ? TOKEN_VARIABLE_TOP_MASK_
	                : 0)
	                | ((top) ? TOKEN_TOP_MASK_ : 0) | before);
	        return m_current_;
	    }
	
	    /// <summary>
	    /// Token before this element
	    /// </summary>
	    ///
	    /// <param name="sourcetoken"></param>
	    /// <param name="strength">collation strength</param>
	    /// <returns>the token before source token</returns>
	    /// <exception cref="ParseException">thrown when rules have the wrong syntax</exception>
	    private CollationRuleParser.Token  GetVirginBefore(CollationRuleParser.Token  sourcetoken, int strength) {
	        // this is a virgin before - we need to fish the anchor from the UCA
	        if (sourcetoken != null) {
	            int offset = sourcetoken.m_source_ & 0xFFFFFF;
	            m_UCAColEIter_.SetText(m_source_.ToString(offset,offset + 1-offset));
	        } else {
	            m_UCAColEIter_.SetText(m_source_.ToString(m_parsedToken_.m_charsOffset_,m_parsedToken_.m_charsOffset_ + 1-m_parsedToken_.m_charsOffset_));
	        }
	
	        int basece = m_UCAColEIter_.Next() & -193;
	        int basecontce = m_UCAColEIter_.Next();
	        if (basecontce == IBM.ICU.Text.CollationElementIterator.NULLORDER) {
	            basecontce = 0;
	        }
	
	        int ch = 0;
	
	        if (((int) (((uint) basece) >> 24) >= RuleBasedCollator.UCA_CONSTANTS_.PRIMARY_IMPLICIT_MIN_)
	                && ((int) (((uint) basece) >> 24) <= RuleBasedCollator.UCA_CONSTANTS_.PRIMARY_IMPLICIT_MAX_)) { /*
	                                                                                                 * implicits
	                                                                                                 * -
	                                                                                                 */
	
	            int primary = basece & IBM.ICU.Text.RuleBasedCollator.CE_PRIMARY_MASK_
	                    | (basecontce & IBM.ICU.Text.RuleBasedCollator.CE_PRIMARY_MASK_) >> 16;
	            int raw = IBM.ICU.Text.RuleBasedCollator.impCEGen_.GetRawFromImplicit(primary);
	            ch = IBM.ICU.Text.RuleBasedCollator.impCEGen_.GetCodePointFromRaw(raw - 1);
	            int primaryCE = IBM.ICU.Text.RuleBasedCollator.impCEGen_
	                    .GetImplicitFromRaw(raw - 1);
	            m_utilCEBuffer_[0] = primaryCE & IBM.ICU.Text.RuleBasedCollator.CE_PRIMARY_MASK_
	                    | 0x0505;
	            m_utilCEBuffer_[1] = (primaryCE << 16)
	                    & IBM.ICU.Text.RuleBasedCollator.CE_PRIMARY_MASK_
	                    | IBM.ICU.Text.RuleBasedCollator.CE_CONTINUATION_MARKER_;
	
	            m_parsedToken_.m_charsOffset_ = m_extraCurrent_;
	            m_source_.Append('\uFFFE');
	            m_source_.Append((char) ch);
	            m_extraCurrent_ += 2;
	            m_parsedToken_.m_charsLen_++;
	
	            m_utilToken_.m_source_ = (m_parsedToken_.m_charsLen_ << 24)
	                    | m_parsedToken_.m_charsOffset_;
	            m_utilToken_.m_rules_ = m_source_;
	            sourcetoken = (CollationRuleParser.Token ) m_hashTable_[m_utilToken_];
	
	            if (sourcetoken == null) {
	                m_listHeader_[m_resultLength_] = new CollationRuleParser.TokenListHeader ();
	                m_listHeader_[m_resultLength_].m_baseCE_ = m_utilCEBuffer_[0] & -193;
	                if (IBM.ICU.Text.RuleBasedCollator.IsContinuation(m_utilCEBuffer_[1])) {
	                    m_listHeader_[m_resultLength_].m_baseContCE_ = m_utilCEBuffer_[1];
	                } else {
	                    m_listHeader_[m_resultLength_].m_baseContCE_ = 0;
	                }
	                m_listHeader_[m_resultLength_].m_nextCE_ = 0;
	                m_listHeader_[m_resultLength_].m_nextContCE_ = 0;
	                m_listHeader_[m_resultLength_].m_previousCE_ = 0;
	                m_listHeader_[m_resultLength_].m_previousContCE_ = 0;
	                m_listHeader_[m_resultLength_].m_indirect_ = false;
	
	                sourcetoken = new CollationRuleParser.Token ();
	                InitAReset(-1, sourcetoken);
	            }
	
	        } else {
	
	            // first ce and second ce m_utilCEBuffer_
	            /* int invpos = */IBM.ICU.Text.CollationParsedRuleBuilder.INVERSE_UCA_
	                    .GetInversePrevCE(basece, basecontce, strength,
	                            m_utilCEBuffer_);
	            // we got the previous CE. Now we need to see if the difference
	            // between
	            // the two CEs is really of the requested strength.
	            // if it's a bigger difference (we asked for secondary and got
	            // primary), we
	            // need to modify the CE.
	            if (IBM.ICU.Text.CollationParsedRuleBuilder.INVERSE_UCA_
	                    .GetCEStrengthDifference(basece, basecontce,
	                            m_utilCEBuffer_[0], m_utilCEBuffer_[1]) < strength) {
	                // adjust the strength
	                // now we are in the situation where our baseCE should actually
	                // be modified in
	                // order to get the CE in the right position.
	                if (strength == IBM.ICU.Text.Collator.SECONDARY) {
	                    m_utilCEBuffer_[0] = basece - 0x0200;
	                } else { // strength == UCOL_TERTIARY
	                    m_utilCEBuffer_[0] = basece - 0x02;
	                }
	                if (IBM.ICU.Text.RuleBasedCollator.IsContinuation(basecontce)) {
	                    if (strength == IBM.ICU.Text.Collator.SECONDARY) {
	                        m_utilCEBuffer_[1] = basecontce - 0x0200;
	                    } else { // strength == UCOL_TERTIARY
	                        m_utilCEBuffer_[1] = basecontce - 0x02;
	                    }
	                }
	            }
	
	            /*
	             * // the code below relies on getting a code point from the inverse
	             * table, in order to be // able to merge the situations like &x < 9
	             * &[before 1]a < d. This won't work: // 1. There are many code
	             * points that have the same CE // 2. The CE to codepoint table
	             * (things pointed to by CETable[3*invPos+2] are broken. // Also, in
	             * case when there is no equivalent strength before an element, we
	             * have to actually // construct one. For example, &[before 2]a << x
	             * won't result in x << a, because the element // before a is a
	             * primary difference. ch =
	             * CollationParsedRuleBuilder.INVERSE_UCA_.m_table_[3 * invpos + 2];
	             * if ((ch & INVERSE_SIZE_MASK_) != 0) { int offset = ch &
	             * INVERSE_OFFSET_MASK_; ch =
	             * CollationParsedRuleBuilder.INVERSE_UCA_.m_continuations_[
	             * offset]; } m_source_.append((char)ch); m_extraCurrent_ ++;
	             * m_parsedToken_.m_charsOffset_ = m_extraCurrent_ - 1;
	             * m_parsedToken_.m_charsLen_ = 1;
	             * 
	             * // We got an UCA before. However, this might have been tailored.
	             * // example: // &\u30ca = \u306a // &[before
	             * 3]\u306a<<<\u306a|\u309d
	             * 
	             * m_utilToken_.m_source_ = (m_parsedToken_.m_charsLen_ << 24) |
	             * m_parsedToken_.m_charsOffset_; m_utilToken_.m_rules_ = m_source_;
	             * sourcetoken = (Token)m_hashTable_.get(m_utilToken_);
	             */
	
	            // here is how it should be. The situation such as &[before 1]a < x,
	            // should be
	            // resolved exactly as if we wrote &a > x.
	            // therefore, I don't really care if the UCA value before a has been
	            // changed.
	            // However, I do care if the strength between my element and the
	            // previous element
	            // is bigger then I wanted. So, if CE < baseCE and I wanted &[before
	            // 2], then i'll
	            // have to construct the base CE.
	
	            // if we found a tailored thing, we have to use the UCA value and
	            // construct a new reset token with constructed name
	            // if (sourcetoken != null && sourcetoken.m_strength_ !=
	            // TOKEN_RESET_) {
	            // character to which we want to anchor is already tailored.
	            // We need to construct a new token which will be the anchor point
	            // m_source_.setCharAt(m_extraCurrent_ - 1, '\uFFFE');
	            // m_source_.append(ch);
	            // m_extraCurrent_ ++;
	            // m_parsedToken_.m_charsLen_ ++;
	            // grab before
	            m_parsedToken_.m_charsOffset_ -= 10;
	            m_parsedToken_.m_charsLen_ += 10;
	            m_listHeader_[m_resultLength_] = new CollationRuleParser.TokenListHeader ();
	            m_listHeader_[m_resultLength_].m_baseCE_ = m_utilCEBuffer_[0] & -193;
	            if (IBM.ICU.Text.RuleBasedCollator.IsContinuation(m_utilCEBuffer_[1])) {
	                m_listHeader_[m_resultLength_].m_baseContCE_ = m_utilCEBuffer_[1];
	            } else {
	                m_listHeader_[m_resultLength_].m_baseContCE_ = 0;
	            }
	            m_listHeader_[m_resultLength_].m_nextCE_ = 0;
	            m_listHeader_[m_resultLength_].m_nextContCE_ = 0;
	            m_listHeader_[m_resultLength_].m_previousCE_ = 0;
	            m_listHeader_[m_resultLength_].m_previousContCE_ = 0;
	            m_listHeader_[m_resultLength_].m_indirect_ = false;
	            sourcetoken = new CollationRuleParser.Token ();
	            InitAReset(-1, sourcetoken);
	            // }
	        }
	        return sourcetoken;
	    }
	
	    /// <summary>
	    /// Processing Description. 1. Build a m_listHeader_. Each list has a header,
	    /// which contains two lists (positive and negative), a reset token, a
	    /// baseCE, nextCE, and previousCE. The lists and reset may be null. 2. As
	    /// you process, you keep a LAST pointer that points to the last token you
	    /// handled.
	    /// </summary>
	    ///
	    /// <param name="expand">string offset, -1 for null strings</param>
	    /// <param name="targetToken">token to update</param>
	    /// <returns>expandnext offset</returns>
	    /// <exception cref="ParseException">thrown when rules syntax failed</exception>
	    private int InitAReset(int expand, CollationRuleParser.Token  targetToken) {
	        if (m_resultLength_ == m_listHeader_.Length - 1) {
	            CollationRuleParser.TokenListHeader [] temp = new CollationRuleParser.TokenListHeader [m_resultLength_ << 1];
	            System.Array.Copy((Array)(m_listHeader_),0,(Array)(temp),0,m_resultLength_ + 1);
	            m_listHeader_ = temp;
	        }
	        // do the reset thing
	        targetToken.m_rules_ = m_source_;
	        targetToken.m_source_ = m_parsedToken_.m_charsLen_ << 24
	                | m_parsedToken_.m_charsOffset_;
	        targetToken.m_expansion_ = m_parsedToken_.m_extensionLen_ << 24
	                | m_parsedToken_.m_extensionOffset_;
	        // keep the flags around so that we know about before
	        targetToken.m_flags_ = m_parsedToken_.m_flags_;
	
	        if (m_parsedToken_.m_prefixOffset_ != 0) {
	            ThrowParseException(m_rules_, m_parsedToken_.m_charsOffset_ - 1);
	        }
	
	        targetToken.m_prefix_ = 0;
	        // TODO: this should also handle reverse
	        targetToken.m_polarity_ = TOKEN_POLARITY_POSITIVE_;
	        targetToken.m_strength_ = TOKEN_RESET_;
	        targetToken.m_next_ = null;
	        targetToken.m_previous_ = null;
	        targetToken.m_CELength_ = 0;
	        targetToken.m_expCELength_ = 0;
	        targetToken.m_listHeader_ = m_listHeader_[m_resultLength_];
	        m_listHeader_[m_resultLength_].m_first_ = null;
	        m_listHeader_[m_resultLength_].m_last_ = null;
	        m_listHeader_[m_resultLength_].m_first_ = null;
	        m_listHeader_[m_resultLength_].m_last_ = null;
	        m_listHeader_[m_resultLength_].m_reset_ = targetToken;
	
	        /*
	         * 3 Consider each item: relation, source, and expansion: e.g. ...< x /
	         * y ... First convert all expansions into normal form. Examples: If
	         * "xy" doesn't occur earlier in the list or in the UCA, convert &xy * c
	         * * d * ... into &x * c/y * d * ... Note: reset values can never have
	         * expansions, although they can cause the very next item to have one.
	         * They may be contractions, if they are found earlier in the list.
	         */
	        int result = 0;
	        if (expand > 0) {
	            // check to see if there is an expansion
	            if (m_parsedToken_.m_charsLen_ > 1) {
	                targetToken.m_source_ = ((expand - m_parsedToken_.m_charsOffset_) << 24)
	                        | m_parsedToken_.m_charsOffset_;
	                result = ((m_parsedToken_.m_charsLen_
	                        + m_parsedToken_.m_charsOffset_ - expand) << 24)
	                        | expand;
	            }
	        }
	
	        m_resultLength_++;
	        ILOG.J2CsMapping.Collections.Collections.Put(m_hashTable_,targetToken,targetToken);
	        return result;
	    }
	
	    /// <summary>
	    /// Checks if an character is special
	    /// </summary>
	    ///
	    /// <param name="ch">character to test</param>
	    /// <returns>true if the character is special</returns>
	    private static bool IsSpecialChar(char ch) {
	        return (ch <= 0x002F && ch >= 0x0020) || (ch <= 0x003F && ch >= 0x003A)
	                || (ch <= 0x0060 && ch >= 0x005B)
	                || (ch <= 0x007E && ch >= 0x007D) || ch == 0x007B;
	    }
	
	    private UnicodeSet ReadAndSetUnicodeSet(String source, int start) {
	        while (source[start] != '[') { /*
	                                               * advance while we find the first
	                                               * '['
	                                               */
	            start++;
	        }
	        // now we need to get a balanced set of '[]'. The problem is that a set
	        // can have
	        // many, and *end point to the first closing '['
	        int noOpenBraces = 1;
	        int current = 1; // skip the opening brace
	        while (start + current < source.Length && noOpenBraces != 0) {
	            if (source[start + current] == '[') {
	                noOpenBraces++;
	            } else if (source[start + current] == ']') { // closing brace
	                noOpenBraces--;
	            }
	            current++;
	        }
	        // int nextBrace = -1;
	
	        if (noOpenBraces != 0
	                || (/* nextBrace = */ILOG.J2CsMapping.Util.StringUtil.IndexOf(source,"]",start + current) /* ']' */) == -1) {
	            ThrowParseException(m_rules_, start);
	        }
	        return new UnicodeSet(source.Substring(start,(start + current)-(start))); // uset_openPattern(start,
	                                                                         // current);
	    }
	
	    /// <summary>
	    /// in C, optionarg is passed by reference to function. We use a private int
	    /// to simulate this.
	    /// </summary>
	    ///
	    private int m_optionarg_;
	
	    private int ReadOption(String rules, int start, int optionend) {
	        m_optionarg_ = 0;
	        int i = 0;
	        while (i < RULES_OPTIONS_.Length) {
	            String option = RULES_OPTIONS_[i].m_name_;
	            int optionlength = option.Length;
	            if (rules.Length > start + optionlength
	                    && option.Equals(rules.Substring(start,(start
	                                                                    + optionlength)-(start)),StringComparison.InvariantCultureIgnoreCase)) {
	                if (optionend - start > optionlength) {
	                    m_optionarg_ = start + optionlength;
	                    // start of the options, skip space
	                    while (m_optionarg_ < optionend
	                            && IBM.ICU.Lang.UCharacter.IsWhitespace(rules[m_optionarg_])) { // eat whitespace
	                        m_optionarg_++;
	                    }
	                }
	                break;
	            }
	            i++;
	        }
	        if (i == RULES_OPTIONS_.Length) {
	            i = -1;
	        }
	        return i;
	    }
	
	    /// <summary>
	    /// Reads and set collation options
	    /// </summary>
	    ///
	    /// <returns>TOKEN_SUCCESS if option is set correct, 0 otherwise</returns>
	    /// <exception cref="ParseException">thrown when options in rules are wrong</exception>
	    private byte ReadAndSetOption() {
	        int start = m_current_ + 1; // skip opening '['
	        int i = ReadOption(m_rules_, start, m_optionEnd_);
	
	        int optionarg = m_optionarg_;
	
	        if (i < 0) {
	            ThrowParseException(m_rules_, start);
	        }
	
	        if (i < 7) {
	            if (optionarg != 0) {
	                for (int j = 0; j < RULES_OPTIONS_[i].m_subOptions_.Length; j++) {
	                    String subname = RULES_OPTIONS_[i].m_subOptions_[j];
	                    int size = optionarg + subname.Length;
	                    if (m_rules_.Length > size
	                            && subname.Equals(m_rules_.Substring(optionarg,(size)-(optionarg)),StringComparison.InvariantCultureIgnoreCase)) {
	                        SetOptions(
	                                m_options_,
	                                RULES_OPTIONS_[i].m_attribute_,
	                                RULES_OPTIONS_[i].m_subOptionAttributeValues_[j]);
	                        return TOKEN_SUCCESS_MASK_;
	                    }
	                }
	            }
	            ThrowParseException(m_rules_, optionarg);
	        } else if (i == 7) { // variable top
	            return TOKEN_SUCCESS_MASK_ | TOKEN_VARIABLE_TOP_MASK_;
	        } else if (i == 8) { // rearange
	            return TOKEN_SUCCESS_MASK_;
	        } else if (i == 9) { // before
	            if (optionarg != 0) {
	                for (int j_0 = 0; j_0 < RULES_OPTIONS_[i].m_subOptions_.Length; j_0++) {
	                    String subname_1 = RULES_OPTIONS_[i].m_subOptions_[j_0];
	                    int size_2 = optionarg + subname_1.Length;
	                    if (m_rules_.Length > size_2
	                            && subname_1.Equals(m_rules_.Substring(optionarg,(optionarg + subname_1.Length)-(optionarg)),StringComparison.InvariantCultureIgnoreCase)) {
	                        return (byte) (TOKEN_SUCCESS_MASK_ | RULES_OPTIONS_[i].m_subOptionAttributeValues_[j_0] + 1);
	                    }
	                }
	            }
	            ThrowParseException(m_rules_, optionarg);
	        } else if (i == 10) { // top, we are going to have an array with
	            // structures of limit CEs index to this array will be
	            // src->parsedToken.indirectIndex
	            m_parsedToken_.m_indirectIndex_ = ((Char)0);
	            return TOKEN_SUCCESS_MASK_ | TOKEN_TOP_MASK_;
	        } else if (i < 13) { // first, last
	            for (int j_3 = 0; j_3 < RULES_OPTIONS_[i].m_subOptions_.Length; j_3++) {
	                String subname_4 = RULES_OPTIONS_[i].m_subOptions_[j_3];
	                int size_5 = optionarg + subname_4.Length;
	                if (m_rules_.Length > size_5
	                        && subname_4.Equals(m_rules_.Substring(optionarg,(size_5)-(optionarg)),StringComparison.InvariantCultureIgnoreCase)) {
	                    m_parsedToken_.m_indirectIndex_ = (char) (i - 10 + (j_3 << 1));
	                    return TOKEN_SUCCESS_MASK_ | TOKEN_TOP_MASK_;
	                }
	            }
	            ThrowParseException(m_rules_, optionarg);
	        } else if (i == 13 || i == 14) { // copy and remove are handled before
	                                         // normalization
	            // we need to move end here
	            int noOpenBraces = 1;
	            m_current_++; // skip opening brace
	            while (m_current_ < m_source_.Length && noOpenBraces != 0) {
	                if (m_source_[m_current_] == '[') {
	                    noOpenBraces++;
	                } else if (m_source_[m_current_] == ']') { // closing
	                                                                  // brace
	                    noOpenBraces--;
	                }
	                m_current_++;
	            }
	            m_optionEnd_ = m_current_ - 1;
	            return TOKEN_SUCCESS_MASK_;
	        } else {
	            ThrowParseException(m_rules_, optionarg);
	        }
	        return TOKEN_SUCCESS_MASK_; // we will never reach here.
	    }
	
	    /// <summary>
	    /// Set collation option
	    /// </summary>
	    ///
	    /// <param name="optionset">option set to set</param>
	    /// <param name="attribute">type to set</param>
	    /// <param name="value">attribute value</param>
	    private void SetOptions(CollationRuleParser.OptionSet  optionset, int attribute, int value_ren) {
	        switch (attribute) {
	        case IBM.ICU.Text.RuleBasedCollator.Attribute.HIRAGANA_QUATERNARY_MODE_:
	            optionset.m_isHiragana4_ = (value_ren == IBM.ICU.Text.RuleBasedCollator.AttributeValue.ON_);
	            break;
	        case IBM.ICU.Text.RuleBasedCollator.Attribute.FRENCH_COLLATION_:
	            optionset.m_isFrenchCollation_ = (value_ren == IBM.ICU.Text.RuleBasedCollator.AttributeValue.ON_);
	            break;
	        case IBM.ICU.Text.RuleBasedCollator.Attribute.ALTERNATE_HANDLING_:
	            optionset.m_isAlternateHandlingShifted_ = (value_ren == IBM.ICU.Text.RuleBasedCollator.AttributeValue.SHIFTED_);
	            break;
	        case IBM.ICU.Text.RuleBasedCollator.Attribute.CASE_FIRST_:
	            optionset.m_caseFirst_ = value_ren;
	            break;
	        case IBM.ICU.Text.RuleBasedCollator.Attribute.CASE_LEVEL_:
	            optionset.m_isCaseLevel_ = (value_ren == IBM.ICU.Text.RuleBasedCollator.AttributeValue.ON_);
	            break;
	        case IBM.ICU.Text.RuleBasedCollator.Attribute.NORMALIZATION_MODE_:
	            if (value_ren == IBM.ICU.Text.RuleBasedCollator.AttributeValue.ON_) {
	                value_ren = IBM.ICU.Text.Collator.CANONICAL_DECOMPOSITION;
	            }
	            optionset.m_decomposition_ = value_ren;
	            break;
	        case IBM.ICU.Text.RuleBasedCollator.Attribute.STRENGTH_:
	            optionset.m_strength_ = value_ren;
	            break;
	        default:
	            break;
	        }
	    }
	
	    internal UnicodeSet GetTailoredSet() {
	        bool startOfRules = true;
	        UnicodeSet tailored = new UnicodeSet();
	        String pattern;
	        CanonicalIterator it = new CanonicalIterator("");
	
	        m_parsedToken_.m_strength_ = TOKEN_UNSET_;
	        int sourcelimit = m_source_.Length;
	        // int expandNext = 0;
	
	        while (m_current_ < sourcelimit) {
	            m_parsedToken_.m_prefixOffset_ = 0;
	            if (ParseNextToken(startOfRules) < 0) {
	                // we have reached the end
	                continue;
	            }
	            startOfRules = false;
	            // The idea is to tokenize the rule set. For each non-reset token,
	            // we add all the canonicaly equivalent FCD sequences
	            if (m_parsedToken_.m_strength_ != TOKEN_RESET_) {
	                it.SetSource(m_source_.ToString(m_parsedToken_.m_charsOffset_,m_parsedToken_.m_charsOffset_
	                                                + m_parsedToken_.m_charsLen_-m_parsedToken_.m_charsOffset_));
	                pattern = it.Next();
	                while (pattern != null) {
	                    if (IBM.ICU.Text.Normalizer.QuickCheck(pattern, IBM.ICU.Text.Normalizer.FCD, 0) != IBM.ICU.Text.Normalizer.NO) {
	                        tailored.Add(pattern);
	                    }
	                    pattern = it.Next();
	                }
	            }
	        }
	        return tailored;
	    }
	
	    private void ExtractSetsFromRules(String rules) {
	        int optionNumber = -1;
	        int setStart = 0;
	        int i = 0;
	        while (i < rules.Length) {
	            if (rules[i] == 0x005B) {
	                optionNumber = ReadOption(rules, i + 1, rules.Length);
	                setStart = m_optionarg_;
	                if (optionNumber == 13) { /* copy - parts of UCA to tailoring */
	                    UnicodeSet newSet = ReadAndSetUnicodeSet(rules, setStart);
	                    if (m_copySet_ == null) {
	                        m_copySet_ = newSet;
	                    } else {
	                        m_copySet_.AddAll(newSet);
	                    }
	                } else if (optionNumber == 14) {
	                    UnicodeSet newSet_0 = ReadAndSetUnicodeSet(rules, setStart);
	                    if (m_removeSet_ == null) {
	                        m_removeSet_ = newSet_0;
	                    } else {
	                        m_removeSet_.AddAll(newSet_0);
	                    }
	                }
	            }
	            i++;
	        }
	    }
	
	    static CollationRuleParser() {
	            INDIRECT_BOUNDARIES_ = new CollationRuleParser.IndirectBoundaries [15];
	            INDIRECT_BOUNDARIES_[0] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.LAST_NON_VARIABLE_,
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_IMPLICIT_);
	            INDIRECT_BOUNDARIES_[1] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_PRIMARY_IGNORABLE_, null);
	            INDIRECT_BOUNDARIES_[2] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.LAST_PRIMARY_IGNORABLE_, null);
	            INDIRECT_BOUNDARIES_[3] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_SECONDARY_IGNORABLE_,
	                    null);
	            INDIRECT_BOUNDARIES_[4] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.LAST_SECONDARY_IGNORABLE_,
	                    null);
	            INDIRECT_BOUNDARIES_[5] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_TERTIARY_IGNORABLE_,
	                    null);
	            INDIRECT_BOUNDARIES_[6] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.LAST_TERTIARY_IGNORABLE_, null);
	            INDIRECT_BOUNDARIES_[7] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_VARIABLE_, null);
	            INDIRECT_BOUNDARIES_[8] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.LAST_VARIABLE_, null);
	            INDIRECT_BOUNDARIES_[9] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_NON_VARIABLE_, null);
	            INDIRECT_BOUNDARIES_[10] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.LAST_NON_VARIABLE_,
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_IMPLICIT_);
	            INDIRECT_BOUNDARIES_[11] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_IMPLICIT_, null);
	            INDIRECT_BOUNDARIES_[12] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.LAST_IMPLICIT_,
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_TRAILING_);
	            INDIRECT_BOUNDARIES_[13] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.FIRST_TRAILING_, null);
	            INDIRECT_BOUNDARIES_[14] = new CollationRuleParser.IndirectBoundaries (
	                    RuleBasedCollator.UCA_CONSTANTS_.LAST_TRAILING_, null);
	            INDIRECT_BOUNDARIES_[14].m_limitCE_ = RuleBasedCollator.UCA_CONSTANTS_.PRIMARY_SPECIAL_MIN_ << 24;
	            RULES_OPTIONS_ = new CollationRuleParser.TokenOption [19];
	            String[] option = { "non-ignorable", "shifted" };
	            int[] value_ren = {
	                    IBM.ICU.Text.RuleBasedCollator.AttributeValue.NON_IGNORABLE_,
	                    IBM.ICU.Text.RuleBasedCollator.AttributeValue.SHIFTED_ };
	            RULES_OPTIONS_[0] = new CollationRuleParser.TokenOption (
	                    "alternate",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.ALTERNATE_HANDLING_,
	                    option, value_ren);
	            option = new String[1];
	            option[0] = "2";
	            value_ren = new int[1];
	            value_ren[0] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.ON_;
	            RULES_OPTIONS_[1] = new CollationRuleParser.TokenOption ("backwards",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.FRENCH_COLLATION_,
	                    option, value_ren);
	            String[] offonoption = new String[2];
	            offonoption[0] = "off";
	            offonoption[1] = "on";
	            int[] offonvalue = new int[2];
	            offonvalue[0] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.OFF_;
	            offonvalue[1] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.ON_;
	            RULES_OPTIONS_[2] = new CollationRuleParser.TokenOption ("caseLevel",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.CASE_LEVEL_,
	                    offonoption, offonvalue);
	            option = new String[3];
	            option[0] = "lower";
	            option[1] = "upper";
	            option[2] = "off";
	            value_ren = new int[3];
	            value_ren[0] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.LOWER_FIRST_;
	            value_ren[1] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.UPPER_FIRST_;
	            value_ren[2] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.OFF_;
	            RULES_OPTIONS_[3] = new CollationRuleParser.TokenOption ("caseFirst",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.CASE_FIRST_,
	                    option, value_ren);
	            RULES_OPTIONS_[4] = new CollationRuleParser.TokenOption (
	                    "normalization",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.NORMALIZATION_MODE_,
	                    offonoption, offonvalue);
	            RULES_OPTIONS_[5] = new CollationRuleParser.TokenOption (
	                    "hiraganaQ",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.HIRAGANA_QUATERNARY_MODE_,
	                    offonoption, offonvalue);
	            option = new String[5];
	            option[0] = "1";
	            option[1] = "2";
	            option[2] = "3";
	            option[3] = "4";
	            option[4] = "I";
	            value_ren = new int[5];
	            value_ren[0] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.PRIMARY_;
	            value_ren[1] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.SECONDARY_;
	            value_ren[2] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.TERTIARY_;
	            value_ren[3] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.QUATERNARY_;
	            value_ren[4] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.IDENTICAL_;
	            RULES_OPTIONS_[6] = new CollationRuleParser.TokenOption ("strength",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.STRENGTH_, option,
	                    value_ren);
	            RULES_OPTIONS_[7] = new CollationRuleParser.TokenOption ("variable top",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	            RULES_OPTIONS_[8] = new CollationRuleParser.TokenOption ("rearrange",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	            option = new String[3];
	            option[0] = "1";
	            option[1] = "2";
	            option[2] = "3";
	            value_ren = new int[3];
	            value_ren[0] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.PRIMARY_;
	            value_ren[1] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.SECONDARY_;
	            value_ren[2] = IBM.ICU.Text.RuleBasedCollator.AttributeValue.TERTIARY_;
	            RULES_OPTIONS_[9] = new CollationRuleParser.TokenOption ("before",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, option,
	                    value_ren);
	            RULES_OPTIONS_[10] = new CollationRuleParser.TokenOption ("top",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	            String[] firstlastoption = new String[7];
	            firstlastoption[0] = "primary";
	            firstlastoption[1] = "secondary";
	            firstlastoption[2] = "tertiary";
	            firstlastoption[3] = "variable";
	            firstlastoption[4] = "regular";
	            firstlastoption[5] = "implicit";
	            firstlastoption[6] = "trailing";
	            int[] firstlastvalue = new int[7];
	            ILOG.J2CsMapping.Collections.Arrays.Fill(firstlastvalue,IBM.ICU.Text.RuleBasedCollator.AttributeValue.PRIMARY_);
	            RULES_OPTIONS_[11] = new CollationRuleParser.TokenOption ("first",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_,
	                    firstlastoption, firstlastvalue);
	            RULES_OPTIONS_[12] = new CollationRuleParser.TokenOption ("last",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_,
	                    firstlastoption, firstlastvalue);
	            RULES_OPTIONS_[13] = new CollationRuleParser.TokenOption ("optimize",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	            RULES_OPTIONS_[14] = new CollationRuleParser.TokenOption ("suppressContractions",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	            RULES_OPTIONS_[15] = new CollationRuleParser.TokenOption ("undefined",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	            RULES_OPTIONS_[16] = new CollationRuleParser.TokenOption ("scriptOrder",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	            RULES_OPTIONS_[17] = new CollationRuleParser.TokenOption ("charsetname",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	            RULES_OPTIONS_[18] = new CollationRuleParser.TokenOption ("charset",
	                    IBM.ICU.Text.RuleBasedCollator.Attribute.LIMIT_, null, null);
	        }
	}
}
